{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.models as models\n",
    "from biogeme.expressions import Beta, DefineVariable\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "\n",
    "df = pd.read_csv('../../Data/SMTO_2015/SMTO_2015_Complete_Input.csv')\n",
    "df = df[df['Level'] != 'Other']\n",
    "school_codes = ['SG', 'SC', 'MI', 'YK','YG', 'RY','OC']\n",
    "df['School'] = df['School'].apply(lambda x: school_codes.index(x))\n",
    "\n",
    "for code in school_codes:\n",
    "    df['Enrol.' + code] = df.apply(lambda x: x['UG.' + code] if x['Level'] == 'UG' else x['Grad.' + code], axis=1)\n",
    "df.columns\n",
    "full_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(name, with_ASCs, combined = True):\n",
    "    database = db.Database(\"SMTO\", df.select_dtypes(include = 'number'))\n",
    "    ASCs, V, av = [], {}, {}\n",
    "    B_DIST = Beta('B_DIST', 0, None, None, 0)\n",
    "    B_ENROL = Beta('B_ENROL', 1, None, None, 1 if with_ASCs else 1)\n",
    "    B_FAM_DIST = Beta('B_FAM_DIST', 0, None, None, 0)\n",
    "\n",
    "    for i in range(len(school_codes)):\n",
    "        code = school_codes[i]\n",
    "        ASCs.append(Beta('ASC_' + code, 0, None, None, 0 if with_ASCs and code != 'SG' else 1))\n",
    "        if combined:\n",
    "            V[i] = ASCs[i] + B_ENROL *  database.variables[\"Enrol.\" + code] + B_DIST * database.variables['Dist.' + code] + B_FAM_DIST * database.variables[\"Dist.\" + code] * database.variables[\"Family\"]\n",
    "        else:\n",
    "            V[i] = ASCs[i] + B_ENROL *  database.variables[\"Enrol.\" + code] + B_DIST * database.variables['Dist.' + code]\n",
    "        av[i] = 1   \n",
    "        \n",
    "    logprob = models.loglogit(V, av, database.variables[\"School\"])\n",
    "    test_dict = {'loglike': logprob, 'weight': database.variables[\"Exp_Segment\"]}\n",
    "    biogeme  = bio.BIOGEME(database,test_dict,numberOfThreads=1)\n",
    "    biogeme.modelName = name\n",
    "    results = biogeme.estimate(saveIterations=True)\n",
    "    betas = results.getBetaValues()\n",
    "    \n",
    "    print(\"Results for \" + name + \" model:\")\n",
    "    print(betas)\n",
    "    print()\n",
    "    return betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SG', 'SC', 'MI', 'YK', 'YG', 'RY', 'OC']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cm(name, betas, with_ASCs, combined = True):\n",
    "    \n",
    "    for i in range(len(school_codes)):\n",
    "        code = school_codes[i]\n",
    "        if with_ASCs:\n",
    "            if combined:\n",
    "                df['V_'+ code] = (betas['ASC_' + code] if code != 'SG' else 0) + betas['B_DIST'] * df['Dist.' + code] + betas['B_FAM_DIST'] * df['Dist.' + code] * df['Family'] + df['Total.' + code]\n",
    "            else:\n",
    "                df['V_'+ code] = (betas['ASC_' + code] if code != 'SG' else 0) + betas['B_DIST'] * df['Dist.' + code] + df['Total.' + code]\n",
    "        else:\n",
    "            if combined:\n",
    "                df['V_'+ code] = betas['B_DIST'] * df['Dist.' + code] + betas['B_FAM_DIST'] * df['Dist.' + code] * df['Family'] + df['Total.' + code] #* betas['B_ENROL']\n",
    "            else:\n",
    "                df['V_'+ code] = betas['B_DIST'] * df['Dist.' + code] + df['Total.' + code] #* betas['B_ENROL']\n",
    "\n",
    "    utils = df.iloc[:,-(len(school_codes)):]\n",
    "    for i in range(len(school_codes)):\n",
    "        code = school_codes[i]\n",
    "        df['P_' + code] = utils.apply(lambda x: math.exp(x['V_' + code]) / sum([math.exp(j) for j in x]), axis = 1)\n",
    "    probs = pd.concat((df['School'], df.iloc[:,-(len(school_codes)):]), axis=1)\n",
    "    \n",
    "    print(\"Softmax confusion matrix for \" + name + \" model:\")\n",
    "    softmax_cm = []\n",
    "    for school in range(len(school_codes)):\n",
    "        softmax_cm.append(probs[probs['School'] == school][['P_' + i for i in school_codes]].sum().values.tolist())\n",
    "        print(*probs[probs['School'] == school][['P_' + i for i in school_codes]].sum().values)\n",
    "    \n",
    "    print(softmax_cm)\n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    for i in range(7):\n",
    "        total += sum(softmax_cm[i])\n",
    "        accuracy += softmax_cm[i][i]\n",
    "    accuracy = accuracy/total\n",
    "    print('\\nAccuracy: ' + str(accuracy))\n",
    "    \n",
    "    \n",
    "    print(\"\\nHardmax confusion matrix for \" + name + \" model:\")\n",
    "    for school in range(len(school_codes)):\n",
    "        print(*[(probs[probs['School'] == school][['P_' + i for i in school_codes]].idxmax(axis = 1) == 'P_' + j).sum() for j in school_codes])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor (x, y) in ((\\'Eric\\', True),(\\'Proposed\\', False)):\\n    df = full_df.copy()\\n    print(\"----------- Combined ----------\")\\n    get_cm(x, run_model(x, y), y)\\n    \\n    #print(\"----------- Family ----------\")\\n    #df = full_df[full_df[\\'Family\\'] == 1]\\n    #get_cm(x, run_model(x, y, False), y, False)\\n    \\n    #print(\"----------- Non-Family ----------\")\\n    #df = full_df[full_df[\\'Family\\'] == 0]\\n    #get_cm(x, run_model(x, y, False), y, False)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for (x, y) in (('Eric', True),('Proposed', False)):\n",
    "    df = full_df.copy()\n",
    "    print(\"----------- Combined ----------\")\n",
    "    get_cm(x, run_model(x, y), y)\n",
    "    \n",
    "    #print(\"----------- Family ----------\")\n",
    "    #df = full_df[full_df['Family'] == 1]\n",
    "    #get_cm(x, run_model(x, y, False), y, False)\n",
    "    \n",
    "    #print(\"----------- Non-Family ----------\")\n",
    "    #df = full_df[full_df['Family'] == 0]\n",
    "    #get_cm(x, run_model(x, y, False), y, False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Combined ----------\n",
      "Results for Proposed model:\n",
      "{'B_DIST': -0.13475000404502052, 'B_FAM_DIST': 0.06520057534791564}\n",
      "\n",
      "Softmax confusion matrix for Proposed model:\n",
      "2762.3145817186514 242.68737848017508 296.78443240017333 995.9139242013098 75.35036598480714 1369.4416187632023 169.5076984516492\n",
      "340.0421421758302 244.73785970551108 29.031502448625687 232.20974981521346 23.933729067630303 183.24417976639728 20.800837020791484\n",
      "289.7081690812989 18.28910492277937 260.2246722240281 196.7741579911264 8.144937867618069 138.1136461672136 18.745311745935535\n",
      "983.2537556531387 165.29098422194528 233.03801714021287 1110.5502476563101 46.749340267359145 484.96720762346905 60.15044743757616\n",
      "115.48317306725038 21.629641109970162 20.55869352945785 83.1328085073063 6.909393615960424 60.30111474840854 6.98517542164639\n",
      "1043.4266453978978 171.96296959196357 207.64587052688952 630.0236373440589 41.0079870219161 547.9988536333345 65.93403648393881\n",
      "196.78339465747308 23.799607735945237 27.450878215530462 86.08326641211431 6.176714571383066 101.9712000216745 12.734938385879298\n",
      "[[2762.3145817186514, 242.68737848017508, 296.78443240017333, 995.9139242013098, 75.35036598480714, 1369.4416187632023, 169.5076984516492], [340.0421421758302, 244.73785970551108, 29.031502448625687, 232.20974981521346, 23.933729067630303, 183.24417976639728, 20.800837020791484], [289.7081690812989, 18.28910492277937, 260.2246722240281, 196.7741579911264, 8.144937867618069, 138.1136461672136, 18.745311745935535], [983.2537556531387, 165.29098422194528, 233.03801714021287, 1110.5502476563101, 46.749340267359145, 484.96720762346905, 60.15044743757616], [115.48317306725038, 21.629641109970162, 20.55869352945785, 83.1328085073063, 6.909393615960424, 60.30111474840854, 6.98517542164639], [1043.4266453978978, 171.96296959196357, 207.64587052688952, 630.0236373440589, 41.0079870219161, 547.9988536333345, 65.93403648393881], [196.78339465747308, 23.799607735945237, 27.450878215530462, 86.08326641211431, 6.176714571383066, 101.9712000216745, 12.734938385879298]]\n",
      "\n",
      "Accuracy: 0.34158520147393856\n",
      "\n",
      "Hardmax confusion matrix for Proposed model:\n",
      "4616 184 75 1037 0 0 0\n",
      "450 334 1 289 0 0 0\n",
      "549 7 188 186 0 0 0\n",
      "1231 115 51 1687 0 0 0\n",
      "185 23 4 103 0 0 0\n",
      "1678 150 32 848 0 0 0\n",
      "324 16 8 107 0 0 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = full_df.copy()\n",
    "print(\"----------- Combined ----------\")\n",
    "get_cm('Proposed', run_model('Proposed', False), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Liv_Arr', 'Children', 'Cars', 'Income', 'Home_Zone', 'School_Name',\n",
       "       'Campus', 'Work', 'Licence', 'Mode', 'Age', 'Faculty', 'School_Type',\n",
       "       'Family', 'Level', 'Status', 'Campus_Zone', 'School', 'Dist.CST',\n",
       "       'Dist.CAS', 'Dist.CPR', 'Dist.CMO', 'Dist.CDV', 'Dist.CEG', 'Dist.CPI',\n",
       "       'Dist.CDS', 'Dist.DOS', 'Dist.DWH', 'Dist.MCM', 'Dist.MCB', 'Dist.MOF',\n",
       "       'Dist.MOS', 'Dist.MOI', 'Dist.OTD', 'Dist.OTN', 'Dist.SHD', 'Dist.SHH',\n",
       "       'Dist.SHT', 'Dist.MI', 'Dist.SC', 'Dist.SG', 'Dist.YK', 'Dist.YG',\n",
       "       'Dist.RY', 'Dist.OC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2019 Data\n",
    "full_df = pd.read_csv('../../Data/SMTO_2019/SMTO_2019_Complete_Input.csv')\n",
    "new_school_codes = full_df['School'].unique().tolist()\n",
    "uni_codes = full_df[full_df['School_Type'] == 'University']['School'].unique().tolist()\n",
    "col_codes = full_df[full_df['School_Type'] == 'College']['School'].unique().tolist()\n",
    "\n",
    "# Convert School column to numeric\n",
    "full_df['School'] = full_df['School'].apply(lambda x: new_school_codes.index(x))\n",
    "\n",
    "# Remove rows with missing information\n",
    "full_df = full_df.dropna(subset = ['Family'])\n",
    "full_df['Family'] = (full_df['Family'] * 1).astype(int)\n",
    "\n",
    "cols_to_keep = ['School', 'Family'] + ['Dist.' + code for code in new_school_codes]\n",
    "new_database = db.Database(\"SMTO_2019\", full_df[cols_to_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../../Data/School_Info_2019_Pred_Enrol.csv' does not exist: b'../../Data/School_Info_2019_Pred_Enrol.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-6c1a65651b94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load enrollment data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0menrol_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../Data/School_Info_2019_Pred_Enrol.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Code'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcode_to_log_enrol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../../Data/School_Info_2019_Pred_Enrol.csv' does not exist: b'../../Data/School_Info_2019_Pred_Enrol.csv'"
     ]
    }
   ],
   "source": [
    "# Load enrollment data\n",
    "enrol_df = pd.read_csv('../../Data/School_Info_2019_Pred_Enrol.csv').set_index('Code')\n",
    "\n",
    "def code_to_log_enrol(code):\n",
    "    \"\"\"\n",
    "    Return natural logarithm of total enrollment of campus with given code\n",
    "    If code is invalid, raise KeyError\n",
    "    If no enrollment information available for that code, return np.nan\n",
    "    \"\"\"\n",
    "    return math.log(enrol_df.loc[code]['Total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_school_codes)):\n",
    "    code = new_school_codes[i]\n",
    "    enrollment = code_to_log_enrol(code)\n",
    "    V[i] = code_to_log_enrol(code) + B_DIST * database.variables['Dist.' + code] + B_FAM_DIST * database.variables[\"Dist.\" + code] * database.variables[\"Family\"]\n",
    "    av[i] = 1\n",
    "           \n",
    "simulate = {'Prob.' + new_school_codes[i]: models.logit(V, av, i) for i in range(len(new_school_codes))}\n",
    "    sim_biogeme = bio.BIOGEME(database, simulate)\n",
    "    probs = sim_biogeme.simulate(betas).set_index(df.index)    \n",
    "    hard_cm, soft_cm = [], []\n",
    "    for i in range(len(codes)):\n",
    "        hard_cm.append([(probs[full_df['School'] == school_nums[i]][['Prob.' + j for j in codes]].idxmax(axis = 1) == 'Prob.' + k).sum() for k in new_school_codes])\n",
    "        soft_cm.append((probs[full_df['School'] == school_nums[i]][['Prob.' + j for j in codes]].sum().values.tolist()))     \n",
    "\n",
    "    print(\"Hardmax Accuracy: {:2.2f} %\".format(get_accuracy(hard_cm)))\n",
    "    print(\"Softmax Accuracy: {:2.2f} %\".format(get_accuracy(soft_cm)))\n",
    "\n",
    "def get_accuracy(cm):\n",
    "    \"\"\"\n",
    "    Given confusion matrix as 2D array, return accuracy\n",
    "    \"\"\"\n",
    "    correct = sum([cm[i][i] for i in range(len(cm))])\n",
    "    return correct/sum(sum(cm,[])) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
