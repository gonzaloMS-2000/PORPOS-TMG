{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Feature Engineering and Selection for Location Choice Model\n",
    "\n",
    "In this notebook, we analyze the distance information to be used for our location choice model. In particular, we do some feature engineering to test various input formats for the random forest classifier. After this, we identify the features which we wish to keep.\n",
    "\n",
    "### Load Data\n",
    "\n",
    "First, let's load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Campus</th>\n",
       "      <th>Level</th>\n",
       "      <th>Status</th>\n",
       "      <th>Mode_Actual</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Licence</th>\n",
       "      <th>Work</th>\n",
       "      <th>Age</th>\n",
       "      <th>Family</th>\n",
       "      <th>Cars</th>\n",
       "      <th>...</th>\n",
       "      <th>Domestic.OC</th>\n",
       "      <th>Admission_Avg.SG</th>\n",
       "      <th>Admission_Avg.SC</th>\n",
       "      <th>Admission_Avg.MI</th>\n",
       "      <th>Admission_Avg.YK</th>\n",
       "      <th>Admission_Avg.YG</th>\n",
       "      <th>Admission_Avg.RY</th>\n",
       "      <th>Admission_Avg.OC</th>\n",
       "      <th>Exp_Segment</th>\n",
       "      <th>Exp_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scarborough (UTSC)</td>\n",
       "      <td>UG</td>\n",
       "      <td>FT</td>\n",
       "      <td>Transit Bus</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>20</td>\n",
       "      <td>Family</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8998</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.383705</td>\n",
       "      <td>0.383705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Downtown Toronto (St. George)</td>\n",
       "      <td>Grad</td>\n",
       "      <td>FT</td>\n",
       "      <td>Walk</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>25</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.986085</td>\n",
       "      <td>0.986085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Downtown Toronto (St. George)</td>\n",
       "      <td>UG</td>\n",
       "      <td>FT</td>\n",
       "      <td>Transit Bus</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>23</td>\n",
       "      <td>Family</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8998</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.919270</td>\n",
       "      <td>0.919270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Downtown Toronto (St. George)</td>\n",
       "      <td>UG</td>\n",
       "      <td>FT</td>\n",
       "      <td>Walk</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>20</td>\n",
       "      <td>Roommates</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8998</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.919270</td>\n",
       "      <td>0.919270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Downtown Toronto (St. George)</td>\n",
       "      <td>Grad</td>\n",
       "      <td>FT</td>\n",
       "      <td>Walk</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>27</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.986085</td>\n",
       "      <td>0.986085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Campus Level Status  Mode_Actual  Gender  Licence  \\\n",
       "0             Scarborough (UTSC)    UG     FT  Transit Bus  Female        0   \n",
       "1  Downtown Toronto (St. George)  Grad     FT         Walk  Female        1   \n",
       "2  Downtown Toronto (St. George)    UG     FT  Transit Bus  Female        1   \n",
       "3  Downtown Toronto (St. George)    UG     FT         Walk    Male        1   \n",
       "4  Downtown Toronto (St. George)  Grad     FT         Walk    Male        1   \n",
       "\n",
       "      Work  Age     Family  Cars  ...  Domestic.OC  Admission_Avg.SG  \\\n",
       "0  Unknown   20     Family     1  ...       0.8998             0.893   \n",
       "1  Unknown   25      Other     0  ...       0.6786             0.893   \n",
       "2  Unknown   23     Family     1  ...       0.8998             0.893   \n",
       "3  Unknown   20  Roommates     0  ...       0.8998             0.893   \n",
       "4  Unknown   27      Other     0  ...       0.6786             0.893   \n",
       "\n",
       "  Admission_Avg.SC Admission_Avg.MI Admission_Avg.YK  Admission_Avg.YG  \\\n",
       "0            0.841             0.83            0.817             0.817   \n",
       "1            0.841             0.83            0.817             0.817   \n",
       "2            0.841             0.83            0.817             0.817   \n",
       "3            0.841             0.83            0.817             0.817   \n",
       "4            0.841             0.83            0.817             0.817   \n",
       "\n",
       "   Admission_Avg.RY  Admission_Avg.OC  Exp_Segment  Exp_Level  \n",
       "0              0.84             0.824     0.383705   0.383705  \n",
       "1              0.84             0.824     0.986085   0.986085  \n",
       "2              0.84             0.824     0.919270   0.919270  \n",
       "3              0.84             0.824     0.919270   0.919270  \n",
       "4              0.84             0.824     0.986085   0.986085  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../Data/SMTO_2015/SMTO_2015_Complete_Input.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "There are several formats in which we can pass distance information into the random forest model. These include:\n",
    "\n",
    "- Standard: Columns containing the distances from each students' home zone to each campus zone  \n",
    "- Closest labels: Columns n from 0 to 6 containing the label of the campus that is nth closest to the students' home zone  \n",
    "- Closest distances: Columns n from 0 to 6 containing the distance to the campus that is nth closest to the students' home zone \n",
    "\n",
    "Note that the closest labels format are one-hot-encoded using `get_dummies()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  'Dist.SG',   'Dist.SC',   'Dist.MI',   'Dist.YK',   'Dist.YG',\n",
       "         'Dist.RY',   'Dist.OC',           0,           1,           2,\n",
       "                 3,           4,           5,           6, '0_Dist.MI',\n",
       "       '0_Dist.OC', '0_Dist.RY', '0_Dist.SC', '0_Dist.SG', '0_Dist.YG',\n",
       "       '0_Dist.YK', '1_Dist.MI', '1_Dist.OC', '1_Dist.RY', '1_Dist.SC',\n",
       "       '1_Dist.SG', '1_Dist.YG', '1_Dist.YK', '2_Dist.MI', '2_Dist.OC',\n",
       "       '2_Dist.RY', '2_Dist.SC', '2_Dist.SG', '2_Dist.YG', '2_Dist.YK',\n",
       "       '3_Dist.MI', '3_Dist.OC', '3_Dist.RY', '3_Dist.SC', '3_Dist.SG',\n",
       "       '3_Dist.YG', '3_Dist.YK', '4_Dist.MI', '4_Dist.OC', '4_Dist.RY',\n",
       "       '4_Dist.SC', '4_Dist.SG', '4_Dist.YG', '4_Dist.YK', '5_Dist.MI',\n",
       "       '5_Dist.OC', '5_Dist.RY', '5_Dist.SC', '5_Dist.YG', '5_Dist.YK',\n",
       "       '6_Dist.MI', '6_Dist.SC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['School_Codes']\n",
    "\n",
    "closest_labels = pd.DataFrame(df.iloc[:, 16:23].apply(lambda x: x.nsmallest(7).index.tolist(), axis=1).tolist(), index=df.index)\n",
    "closest_distances = pd.DataFrame(df.iloc[:, 16:23].apply(lambda x: x.nsmallest(7).tolist(), axis=1).tolist(), index=df.index)\n",
    "x = pd.concat((df.iloc[:, 16:23], closest_labels, closest_distances), axis=1)\n",
    "x = pd.get_dummies(x)\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Model\n",
    "\n",
    "Now, let us run the model with all of the extracted features. We report the following performance metrics:\n",
    "\n",
    "- Accuracy: The accuracy of the model, also the micro precision/recall/f-1 score  \n",
    "- PRF1 Mac: The macro precision, recall, and f-1 score  \n",
    "- Matthews: The Matthews Correlation Coefficient (MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\t 0.4586175534333788\n",
      "PRF1 Mac\t (0.37854012613995025, 0.31216688125447584, 0.321015143183594)\n",
      "Matthews\t 0.24392244699637025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\\t\", rf.score(X_test, y_test)) # Acc\n",
    "print(\"PRF1 Mac\\t\", precision_recall_fscore_support(y_test, y_pred, average = 'macro')[:3]) # Rec = Bal Acc\n",
    "print(\"Matthews\\t\", matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "Now, we can take a look at which features were most important. We analyze two such metrics:\n",
    "\n",
    "- FeatImportance: The impurity-based feature importances  \n",
    "- PermImportance: The permutation importance of each feature, averaged over 5 trials  \n",
    "\n",
    "Including the permutation importance acts as a way to mitigate the bias towards high-cardinality features from the impourity-based feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FeatImportance</th>\n",
       "      <th>PermImportance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dist.SG</th>\n",
       "      <td>0.071306</td>\n",
       "      <td>0.002709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dist.SC</th>\n",
       "      <td>0.062737</td>\n",
       "      <td>0.003937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dist.MI</th>\n",
       "      <td>0.056874</td>\n",
       "      <td>0.002495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dist.YK</th>\n",
       "      <td>0.066629</td>\n",
       "      <td>0.005282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dist.YG</th>\n",
       "      <td>0.047530</td>\n",
       "      <td>0.001813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FeatImportance  PermImportance\n",
       "Dist.SG        0.071306        0.002709\n",
       "Dist.SC        0.062737        0.003937\n",
       "Dist.MI        0.056874        0.002495\n",
       "Dist.YK        0.066629        0.005282\n",
       "Dist.YG        0.047530        0.001813"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame(index = X_test.columns)\n",
    "features['FeatImportance'] = rf.feature_importances_\n",
    "\n",
    "result = permutation_importance(rf, X_train, y_train)\n",
    "features['PermImportance'] = result.importances_mean\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've generated a dataframe containing the importance metrics for each feature. Let's see which features were identified as most important by each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0_Dist.MI', '1', '2', '5', '5_Dist.MI', '6', 'Dist.MI', 'Dist.OC', 'Dist.RY', 'Dist.SC', 'Dist.SG', 'Dist.YG', 'Dist.YK']\n",
      "['0', '1', '2', '3', '4', '5', '6', 'Dist.MI', 'Dist.OC', 'Dist.RY', 'Dist.SC', 'Dist.SG', 'Dist.YG', 'Dist.YK']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(list(map(str, list(features['PermImportance'].sort_values(ascending=False)[:14].index)))))\n",
    "print(sorted(list(map(str, list(features['FeatImportance'].sort_values(ascending=False)[:14].index)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we see that both metrics agree on which 14 features are most important. These are the standard distances and closest distances.\n",
    "\n",
    "### Verification\n",
    "\n",
    "To verify this finding, we can use `sklearn`'s `SelectFromModel`. Notice that these produce the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', 'Dist.MI', 'Dist.OC', 'Dist.RY', 'Dist.SC', 'Dist.SG', 'Dist.YG', 'Dist.YK']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
    "sel.fit(X_train, y_train)\n",
    "print(sorted(list(map(str, list(X_train.columns[(sel.get_support())])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compare the results using all the extracted features with the results using only the selected ones, and using only standard distances (the benchmark model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Benchmark model:\n",
      "Accuracy\t 0.4560936789449749 \t 0.005224099798199897\n",
      "Prec Mac\t 0.3371474593284371 \t 0.0206911857546598\n",
      "Rec  Mac\t 0.29799048903053954 \t 0.006142840523763042\n",
      "F-1  Mac\t 0.3000913243560917 \t 0.00844401896986435\n",
      "Matthews\t 0.23602959667377524 \t 0.006795194377594011\n",
      "Ave Prob\t 0.3831216755576636 \t 0.0032419106926779196\n",
      "\n",
      "Results for Selected model:\n",
      "Accuracy\t 0.45798090040927686 \t 0.006641907457464536\n",
      "Prec Mac\t 0.3409157638330924 \t 0.021410468845564315\n",
      "Rec  Mac\t 0.30083099769117055 \t 0.008598171519038312\n",
      "F-1  Mac\t 0.30532814260275487 \t 0.00896481143771878\n",
      "Matthews\t 0.24030387413679843 \t 0.009463891424651873\n",
      "Ave Prob\t 0.3850053870512864 \t 0.003163422738580068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from statistics import stdev\n",
    "def average(l):\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "\n",
    "schools = list(rf.classes_)\n",
    "\n",
    "for x_temp, name in ((x.iloc[:, :7], \"Benchmark\"), (x.iloc[:, :14], \"Selected\"), (x, \"Full\")):\n",
    "    acc = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    f_1 = []\n",
    "    mcc = []\n",
    "    apo = []\n",
    "    for i in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x_temp, y, test_size=0.3)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)        \n",
    "        acc.append(rf.score(X_test, y_test))\n",
    "        p, r, f = precision_recall_fscore_support(y_test, y_pred, average = 'macro')[:3]\n",
    "        prec.append(p)\n",
    "        rec.append(r)\n",
    "        f_1.append(f)\n",
    "        mcc.append(matthews_corrcoef(y_test, y_pred))\n",
    "        probs = rf.predict_proba(X_test)\n",
    "        results = pd.concat((y_test.reset_index(drop=True), pd.DataFrame(probs)), axis=1)\n",
    "        apo.append(results.apply(lambda z: z[schools.index(z.School_Codes)], axis=1).mean())\n",
    "        \n",
    "    \n",
    "    print(\"Results for \" + name + \" model:\")\n",
    "    print(\"Accuracy\\t\", average(acc), \"\\t\", stdev(acc))\n",
    "    print(\"Prec Mac\\t\", average(prec), \"\\t\", stdev(prec))\n",
    "    print(\"Rec  Mac\\t\", average(rec), \"\\t\", stdev(rec))\n",
    "    print(\"F-1  Mac\\t\", average(f_1), \"\\t\", stdev(f_1))\n",
    "    print(\"Matthews\\t\", average(mcc), \"\\t\", stdev(mcc))\n",
    "    print(\"Ave Prob\\t\", average(apo), \"\\t\", stdev(apo))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results, we see that the model with the selected features indeed outperforms the benchmark model. We also see that the Full model performed similarly to the Benchmark model, suggesting potential overfitting in the training process.\n",
    "\n",
    "To further refine this feature selection process, let us look at how accuracy changes for different numbers of campuses included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    x_temp = x.iloc[:, :8+i]\n",
    "    name = str(i+1) + \" Closest\"\n",
    "    acc = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    f_1 = []\n",
    "    mcc = []\n",
    "    apo = []\n",
    "    for i in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x_temp, y, test_size=0.3)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)        \n",
    "        acc.append(rf.score(X_test, y_test))\n",
    "        p, r, f = precision_recall_fscore_support(y_test, y_pred, average = 'macro')[:3]\n",
    "        prec.append(p)\n",
    "        rec.append(r)\n",
    "        f_1.append(f)\n",
    "        mcc.append(matthews_corrcoef(y_test, y_pred))\n",
    "        probs = rf.predict_proba(X_test)\n",
    "        results = pd.concat((y_test.reset_index(drop=True), pd.DataFrame(probs)), axis=1)\n",
    "        apo.append(results.apply(lambda z: z[schools.index(z.School_Codes)], axis=1).mean())\n",
    "        \n",
    "    \n",
    "    print(\"Results for \" + name + \" model:\")\n",
    "    print(\"Accuracy\\t\", average(acc), \"\\t\", stdev(acc))\n",
    "    print(\"Prec Mac\\t\", average(prec), \"\\t\", stdev(prec))\n",
    "    print(\"Rec  Mac\\t\", average(rec), \"\\t\", stdev(rec))\n",
    "    print(\"F-1  Mac\\t\", average(f_1), \"\\t\", stdev(f_1))\n",
    "    print(\"Matthews\\t\", average(mcc), \"\\t\", stdev(mcc))\n",
    "    print(\"Ave Prob\\t\", average(apo), \"\\t\", stdev(apo))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that while the effectiveness of the model fluctuates for different numbers of labels included, these changes are not significant.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Some next steps include:\n",
    "\n",
    "- Tune hyperparameters (tree depth, splitting criterion, etc.)\n",
    "- Introduce additional variables and perform feature engineering and selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
