{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data, including normalized zone coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../Data/SMTO_2015/SMTO_2015_Complete_Input.csv')\n",
    "df = df[df['Level'] != 'Other']\n",
    "\n",
    "zones = pd.read_csv('../../Data/Zones.csv').set_index('Zone#')\n",
    "temp = pd.DataFrame([[a[i] for a in (zones['PD'], zones['X'], zones['Y'])] for i in df['HomeZone']], columns=['PD', 'X', 'Y'], index=df.index)\n",
    "df = pd.concat((df, temp), axis=1)\n",
    "\n",
    "df['X'] = (df['X'] - df['X'].min()) / (df['X'].max() - df['X'].min())\n",
    "df['Y'] = (df['Y'] - df['Y'].min()) / (df['Y'].max() - df['Y'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "std_dists = df.iloc[:, 17:24]\n",
    "three_dists = df.iloc[:,18:21] # YK, SC, MI\n",
    "coords = df[['X', 'Y']]\n",
    "\n",
    "X = pd.concat((std_dists, df.Segment), axis=1)\n",
    "y = df['School_Codes']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance metrics calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "def evaluate_model(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    probs = pd.concat((y_test.reset_index(drop=True), pd.DataFrame(model.predict_proba(X_test))), axis=1)\n",
    "    schools = list(model.classes_)\n",
    "    metrics_list = [model.score(X_test, y_test)]      \n",
    "    metrics_list.extend(precision_recall_fscore_support(y_test, preds, average = 'macro')[:3])\n",
    "    metrics_list.append(matthews_corrcoef(y_test, preds))\n",
    "    metrics_list.append(probs.apply(lambda z: z[schools.index(z.School_Codes)], axis=1).mean())\n",
    "    return metrics_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate base model with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "metric_names = ['Acc', 'Prec', 'Rec', 'F1', 'MCC', 'APO']\n",
    "results = pd.DataFrame(columns=['Model'] + metric_names)\n",
    "\n",
    "base_rf = RandomForestClassifier()\n",
    "results.loc[len(results)] = ['Base'] + evaluate_model(base_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning.\n",
    "\n",
    "Code adapted from https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 62,\n",
       " 'min_samples_split': 14,\n",
       " 'min_samples_leaf': 11,\n",
       " 'max_features': 0.3,\n",
       " 'max_depth': 9,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_grid = {'n_estimators': [x for x in range(1, 101)],\n",
    "               'max_features': ['auto', 'log2', 0.3],\n",
    "               'max_depth': [x for x in range(1, 16)] + [None],\n",
    "               'min_samples_split': [x for x in range(2, 22, 2)],\n",
    "               'min_samples_leaf': [x for x in range(1, 21)],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, n_jobs = -1)\n",
    "rf_random.fit(pd.concat((std_dists, df.Segment), axis=1), df['School_Codes'])\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model suggested by randomized search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>APO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.476555</td>\n",
       "      <td>0.318752</td>\n",
       "      <td>0.311349</td>\n",
       "      <td>0.308958</td>\n",
       "      <td>0.271625</td>\n",
       "      <td>0.413734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BestRand</td>\n",
       "      <td>0.512535</td>\n",
       "      <td>0.419399</td>\n",
       "      <td>0.341073</td>\n",
       "      <td>0.326994</td>\n",
       "      <td>0.315704</td>\n",
       "      <td>0.398808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model       Acc      Prec       Rec        F1       MCC       APO\n",
       "0      Base  0.476555  0.318752  0.311349  0.308958  0.271625  0.413734\n",
       "1  BestRand  0.512535  0.419399  0.341073  0.326994  0.315704  0.398808"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = rf_random.best_estimator_\n",
    "results.loc[len(results)] = ['BestRand'] + evaluate_model(best_rf)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refined grid search near recommended parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7,\n",
       " 'min_samples_leaf': 13,\n",
       " 'min_samples_split': 14,\n",
       " 'n_estimators': 60}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [50, 60, 70],\n",
    "               'max_depth': [7, 8, 9, 10],\n",
    "               'min_samples_split': [13, 14, 15, 16, 17, 18],\n",
    "               'min_samples_leaf': [10, 11, 12, 13]}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(pd.concat((std_dists, df.Segment), axis=1), df['School_Codes'])\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from recommended model from grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>APO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.476555</td>\n",
       "      <td>0.318752</td>\n",
       "      <td>0.311349</td>\n",
       "      <td>0.308958</td>\n",
       "      <td>0.271625</td>\n",
       "      <td>0.413734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BestRand</td>\n",
       "      <td>0.512535</td>\n",
       "      <td>0.419399</td>\n",
       "      <td>0.341073</td>\n",
       "      <td>0.326994</td>\n",
       "      <td>0.315704</td>\n",
       "      <td>0.398808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BestGrid</td>\n",
       "      <td>0.506732</td>\n",
       "      <td>0.458346</td>\n",
       "      <td>0.328039</td>\n",
       "      <td>0.310877</td>\n",
       "      <td>0.302909</td>\n",
       "      <td>0.388046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model       Acc      Prec       Rec        F1       MCC       APO\n",
       "0      Base  0.476555  0.318752  0.311349  0.308958  0.271625  0.413734\n",
       "1  BestRand  0.512535  0.419399  0.341073  0.326994  0.315704  0.398808\n",
       "2  BestGrid  0.506732  0.458346  0.328039  0.310877  0.302909  0.388046"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = grid_search.best_estimator_\n",
    "results.loc[len(results)] = ['BestGrid'] + evaluate_model(best_rf)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
